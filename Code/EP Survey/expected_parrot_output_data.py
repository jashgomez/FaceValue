# -*- coding: utf-8 -*-
"""Expected Parrot Output Data

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mysYXRRr5IiQKbFT9yD0ivxE9YM4I2Df

# Process Output Data obtained from Expected Parrot
# Collect averages, to get AI-based investor expectation
# Compare expected performance with actual performance
"""

from google.colab import drive
import pandas as pd
# File in/out access
drive.mount('/content/drive')

# Load the CEO data
dir = "/content/drive/MyDrive/Colab Notebooks/Axion FIN 377 Final Project/ExpectedParrot/"
df = pd.read_csv(dir+"ceo_survey_results.csv",
                 names = ['scenario.CEO', 'scenario.Year', 'scenario.Age', 'scenario.dominant_gender', 'scenario.dominant_race','scenario.dominant_emotion',
                           'answer.Projected_risk_taking', 'answer.Projected_leadership_strength', 'answer.Projected_communication_skill',
                           'answer.Projected_financial_stewardship'])

ceo_results_df = pd.read_csv(dir+"ceo_survey_results.csv") # Added this line to define firm_df

ceo_results_df

"""# Task
Calculate the average of 'answer.Projected_risk_taking', 'answer.Projected_leadership_strength', 'answer.Projected_communication_skill', and 'answer.Projected_financial_stewardship' columns in `ceo_results_df` to create a new column 'expected_performance_factor', and then display the head of `ceo_results_df`.

## Calculate Average Investor Expectation
"""

projected_columns = [
    'answer.Projected_risk_taking',
    'answer.Projected_leadership_strength',
    'answer.Projected_communication_skill',
    'answer.Projected_financial_stewardship'
]
ceo_results_df['expected_performance_factor'] = ceo_results_df[projected_columns].mean(axis=1)
ceo_results_df.head()

ceo_results_df

unique_ceo_names = ceo_results_df['scenario.CEO'].nunique()
print(f"Number of unique CEO names in ceo_results_df: {unique_ceo_names}")

#calculate average 'expected_performance_factor' per CEO
ceo_average_expected_performance = ceo_results_df.groupby('scenario.CEO')['expected_performance_factor'].mean()
print("Average expected performance factor per CEO:")
display(ceo_average_expected_performance.head())

"""# Compare Expected Performance with Actual Performance"""

# get firm data (Year_Cum_Ret_Overall, Tenure_Cum_Ret_Overall)
# Load CEO firm Data


dir = "/content/drive/MyDrive/Colab Notebooks/Axion FIN 377 Final Project/inputs/"
df = pd.read_csv(dir + "ceo_year_returns.csv",
                 names = ['Date', 'Year', 'Ticker', 'Company', 'CEO', 'Return' , 'Year_Cum_Ret_Daily' , 'Tenure_Cum_Ret_Daily', 'Year_Cum_Ret_Overall', 'Tenure_Cum_Ret_Overall' ],
                 low_memory=False)

firm_df = pd.read_csv(dir+ "ceo_year_returns.csv", low_memory=False) # Added this line to define firm_df

firm_df

"""# Merge firm and CEO datasets"""

# Rename to match ceo_results_df
firm_df_renamed = firm_df.rename(columns={
    'CEO': 'scenario.CEO',
    'Year': 'scenario.Year'
})

# Merge one-to-one
merged_df = pd.merge(
    ceo_results_df,
    firm_df_renamed,
    on=['scenario.CEO', 'scenario.Year'],
    how='left'
)

merged_df

unique_ceo_names = merged_df['scenario.CEO'].nunique()
print(f"Number of unique CEO names: {unique_ceo_names}")

unique_years = merged_df['scenario.Year'].nunique()
print(f"Number of unique years: {unique_years}")

unique_tickers = merged_df['Ticker'].nunique()
print(f"Number of unique tickers: {unique_tickers}")

merged_df.isna().mean()

clean_df = merged_df.dropna(subset=[
    'Ticker',
    'mean_daily_return',
    'final_year_cum_ret_daily'
])
clean_df

"""## Summary:

### Data Analysis Key Findings
*   A new DataFrame, `aggregated_df`, was successfully created by grouping the original data by 'Ticker' and 'scenario.Year' and then taking the first value for all other columns within each group.
*   The `aggregated_df` consolidates CEO-year expected performance scores, CEO-year demographic traits, and firm-year performance metrics into a single row for each unique Ticker-Year combination.
*   The resulting DataFrame includes columns such as 'Ticker', 'scenario.Year', 'scenario.CEO', 'scenario.Age', 'scenario.dominant\_gender', 'scenario.dominant\_race', 'scenario.dominant\_emotion', various `answer.Projected_` metrics, 'expected\_performance\_factor', 'Date', 'Company', 'Return', 'Year\_Cum\_Ret\_Daily', 'Tenure\_Cum\_Ret\_Daily', 'Year\_Cum\_Ret\_Overall', and 'Tenure\_Cum\_Ret\_Overall'.

### Insights or Next Steps
*   The `aggregated_df` provides a structured dataset suitable for analyzing the relationship between CEO characteristics, projected performance, and actual firm performance on an annual basis.
*   Further analysis can now proceed to explore correlations or build predictive models using this aggregated, time-series-like data.

# Task
Install the `yfinance` library, import it, extract unique tickers from `aggregated_df`, fetch detailed stock information (industry, sector, market cap, employee count) for these tickers using `yfinance`, merge this information with `aggregated_df` based on the 'Ticker' column, and then display the head of the updated `aggregated_df`.

## Install yfinance

### Subtask:
Install the yfinance library if not already installed.

**Reasoning**:
The subtask is to install the yfinance library. This can be achieved by running the pip install command in a code cell.
"""

import yfinance as yf

"""## Extract Unique Tickers

### Subtask:
Identify all unique stock tickers present in the `aggregated_df`.

**Reasoning**:
To identify all unique stock tickers, I will access the 'Ticker' column of `aggregated_df` and use the `.unique()` method to extract distinct values, storing them in a new variable `unique_tickers`.
"""

unique_tickers = clean_df['Ticker'].unique()
print(f"Found {len(unique_tickers)} unique tickers:")
print(unique_tickers)

stock_info_list = []
for ticker_symbol in unique_tickers:
    ticker = yf.Ticker(ticker_symbol)
    info = ticker.info
    stock_info_list.append({
        'Ticker': ticker_symbol,
        'Industry': info.get('industry'),
        'Sector': info.get('sector'),
        'Market_Cap': info.get('marketCap'),
        'Full_Time_Employees': info.get('fullTimeEmployees')
    })

stock_details_df = pd.DataFrame(stock_info_list)
print("Fetched stock details for all unique tickers.")
display(stock_details_df.head())

"""**Reasoning**:
The detailed stock information has been fetched and stored in `stock_details_df`. The next logical step is to merge this `stock_details_df` with the `aggregated_df` using the 'Ticker' column as the key, as specified by the main task, and then display the head of the merged DataFrame.


"""

# Check for duplicates in the stock details
duplicates = stock_details_df.duplicated(subset=['Ticker'], keep=False)
stock_details_df[duplicates]
# Keep the first row for each ticker
stock_details_df_unique = stock_details_df.drop_duplicates(subset=['Ticker'])

clean_df = pd.merge(clean_df, stock_details_df, on='Ticker', how='left')
display(clean_df.head())

clean_df.columns
#clean_df

clean_df = clean_df.rename(columns={
    'mean_daily_return': 'Return',
    'final_year_cum_ret_daily': 'Year_Cum_Ret_Daily',
    'final_tenure_cum_ret_daily': 'Tenure_Cum_Ret_Daily',
    'year_cum_ret_overall': 'Year_Cum_Ret_Overall',
    'tenure_cum_ret_overall': 'Tenure_Cum_Ret_Overall'
})

display(clean_df.head())

output_path = dir + "clean_data_with_stock_info.csv"
clean_df.to_csv(output_path, index=False)
print(f"clean_df saved to: {output_path}")

"""## Summary:

### Data Analysis Key Findings
*   A total of 46 unique stock tickers were identified from the `aggregated_df`.
*   The `yfinance` library was confirmed to be already installed in the environment.
*   Detailed stock information, including 'Industry', 'Sector', 'Market\_Cap', and 'Full\_Time\_Employees', was successfully retrieved for all 46 unique tickers.
*   The `aggregated_df` was successfully augmented by merging the fetched stock details, now containing industry, sector, market capitalization, and employee count for each ticker.

### Insights or Next Steps
*   The enriched `aggregated_df` now allows for more granular analysis, such as comparing stock performance across different industries or sectors, or analyzing trends based on company size (market cap, employee count).
*   Further analysis could involve exploring correlations between these new financial and categorical features and existing stock performance metrics within the `aggregated_df`.

"""